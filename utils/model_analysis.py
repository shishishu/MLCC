"""
æ¨¡å‹åˆ†æå·¥å…·ï¼šè®¡ç®—æ¨¡å‹å¤§å°ã€å‚æ•°é‡ã€FLOPsç­‰æŒ‡æ ‡
"""

import torch
import torch.nn as nn
import os
from typing import Dict, Tuple, Any
from thop import profile, clever_format


def analyze_model_size(model: nn.Module, checkpoint_path: str = None) -> Dict[str, Any]:
    """
    åˆ†ææ¨¡å‹å¤§å°ï¼ŒåŒºåˆ†embeddingå’Œå…¶ä»–å‚æ•°

    Args:
        model: PyTorchæ¨¡å‹
        checkpoint_path: æ¨¡å‹checkpointæ–‡ä»¶è·¯å¾„

    Returns:
        åŒ…å«å„ç§å¤§å°æŒ‡æ ‡çš„å­—å…¸
    """
    results = {}

    # 1. å‚æ•°ç»Ÿè®¡ - åŒºåˆ†sparseå’Œdenseå‚æ•°
    total_params = 0
    sparse_params = 0  # embedding tableå‚æ•°
    dense_params = 0   # ç½‘ç»œå±‚å‚æ•°

    for name, param in model.named_parameters():
        param_count = param.numel()
        total_params += param_count

        if 'embedding' in name.lower():
            sparse_params += param_count
        else:
            dense_params += param_count

    results['parameters'] = {
        'total': total_params,
        'sparse_embedding': sparse_params,
        'dense_network': dense_params,
        'sparse_ratio': sparse_params / total_params if total_params > 0 else 0
    }

    # 2. å†…å­˜å¤§å°ï¼ˆå‚æ•°ï¼‰
    # å‡è®¾æ¯ä¸ªå‚æ•°4å­—èŠ‚ï¼ˆfloat32ï¼‰
    bytes_per_param = 4
    results['memory_size'] = {
        'total_mb': total_params * bytes_per_param / (1024 * 1024),
        'embedding_mb': sparse_params * bytes_per_param / (1024 * 1024),
        'other_mb': dense_params * bytes_per_param / (1024 * 1024)
    }

    # 3. æ–‡ä»¶å¤§å°ï¼ˆå¦‚æœæœ‰checkpointï¼‰
    if checkpoint_path and os.path.exists(checkpoint_path):
        file_size_bytes = os.path.getsize(checkpoint_path)
        results['file_size'] = {
            'total_mb': file_size_bytes / (1024 * 1024),
            'total_gb': file_size_bytes / (1024 * 1024 * 1024)
        }

    return results


def analyze_model_flops(model: nn.Module, input_shape: Tuple[int, ...]) -> Dict[str, Any]:
    """
    åˆ†ææ¨¡å‹FLOPs

    Args:
        model: PyTorchæ¨¡å‹
        input_shape: è¾“å…¥å¼ é‡å½¢çŠ¶ (batch_size, features)

    Returns:
        åŒ…å«FLOPsæŒ‡æ ‡çš„å­—å…¸
    """
    results = {}

    # åˆ›å»ºç¤ºä¾‹è¾“å…¥ï¼Œç¡®ä¿ä¸æ¨¡å‹åœ¨åŒä¸€è®¾å¤‡
    device = next(model.parameters()).device
    dummy_input = torch.randint(0, 1000, input_shape, dtype=torch.long, device=device)

    # è®¡ç®—FLOPs
    model.eval()
    try:
        flops, params = profile(model, inputs=(dummy_input,), verbose=False)

        # æ ¼å¼åŒ–ç»“æœ
        flops_formatted, params_formatted = clever_format([flops, params], "%.3f")

        per_example_flops = flops / input_shape[0] if input_shape[0] > 0 else flops

        results['flops'] = {
            'total': flops,
            'total_formatted': flops_formatted,
            'per_example': per_example_flops,
            'per_example_formatted': f"{per_example_flops:,.0f}"  # ç›´æ¥æ ¼å¼åŒ–ï¼Œä¸ä½¿ç”¨clever_format
        }

        results['thop_params'] = {
            'total': params,
            'total_formatted': params_formatted
        }

    except Exception as e:
        results['error'] = f"FLOPsè®¡ç®—å¤±è´¥: {str(e)}"

    return results


def print_model_analysis(model: nn.Module, checkpoint_path: str = None,
                        input_shape: Tuple[int, ...] = (1, 39)) -> None:
    """
    æ‰“å°å®Œæ•´çš„æ¨¡å‹åˆ†ææŠ¥å‘Š

    Args:
        model: PyTorchæ¨¡å‹
        checkpoint_path: checkpointæ–‡ä»¶è·¯å¾„
        input_shape: è¾“å…¥å½¢çŠ¶
    """
    print("=" * 60)
    print("æ¨¡å‹åˆ†ææŠ¥å‘Š")
    print("=" * 60)

    # 1. æ¨¡å‹å¤§å°åˆ†æ
    size_analysis = analyze_model_size(model, checkpoint_path)

    print("\nğŸ“Š å‚æ•°ç»Ÿè®¡:")
    params = size_analysis['parameters']
    print(f"  æ€»å‚æ•°é‡: {params['total']:,}")
    print(f"  Embedding Table (Sparse)å‚æ•°: {params['sparse_embedding']:,} ({params['sparse_ratio']:.2%})")
    print(f"  ç½‘ç»œå±‚(Dense)å‚æ•°: {params['dense_network']:,} ({(1-params['sparse_ratio']):.2%})")

    print("\nğŸ’¾ å†…å­˜å ç”¨:")
    memory = size_analysis['memory_size']
    print(f"  æ€»å†…å­˜: {memory['total_mb']:.1f} MB")
    print(f"  Embeddingå†…å­˜: {memory['embedding_mb']:.1f} MB")
    print(f"  ç½‘ç»œå±‚å†…å­˜: {memory['other_mb']:.1f} MB")

    if 'file_size' in size_analysis:
        print("\nğŸ“ æ–‡ä»¶å¤§å°:")
        file_size = size_analysis['file_size']
        print(f"  Checkpointå¤§å°: {file_size['total_mb']:.1f} MB ({file_size['total_gb']:.2f} GB)")

    # 2. FLOPsåˆ†æ
    flops_analysis = analyze_model_flops(model, input_shape)

    if 'error' not in flops_analysis:
        print("\nâš¡ è®¡ç®—å¤æ‚åº¦:")
        flops = flops_analysis['flops']
        print(f"  æ€»FLOPs: {flops['total_formatted']}")
        print(f"  æ¯æ ·æœ¬FLOPs: {flops['per_example_formatted']}")

        # è®¡ç®—æ¨ç†é€Ÿåº¦ä¼°ç®—ï¼ˆç²—ç•¥ï¼‰
        estimated_ops_per_sec = 1e12  # å‡è®¾1T OPS/sec
        estimated_samples_per_sec = estimated_ops_per_sec / flops['per_example']
        print(f"  ä¼°ç®—æ¨ç†é€Ÿåº¦: {estimated_samples_per_sec:,.0f} samples/sec")
    else:
        print(f"\nâŒ FLOPsè®¡ç®—: {flops_analysis['error']}")

    print("\n" + "=" * 60)


def compare_models_efficiency(models_info: Dict[str, Dict]) -> None:
    """
    æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„æ•ˆç‡æŒ‡æ ‡

    Args:
        models_info: {model_name: {'model': model, 'checkpoint': path, 'metrics': {...}}}
    """
    print("=" * 80)
    print("æ¨¡å‹æ•ˆç‡å¯¹æ¯”")
    print("=" * 80)

    # æ‰“å°è¡¨å¤´
    print(f"{'æ¨¡å‹':<15} {'å‚æ•°é‡':<12} {'æ–‡ä»¶å¤§å°':<12} {'FLOPs/æ ·æœ¬':<15} {'AUC':<8}")
    print("-" * 75)

    for name, info in models_info.items():
        model = info['model']
        checkpoint = info.get('checkpoint')
        metrics = info.get('metrics', {})

        # è·å–åŸºæœ¬ä¿¡æ¯
        size_info = analyze_model_size(model, checkpoint)
        flops_info = analyze_model_flops(model, (1, 39))

        params = f"{size_info['parameters']['total']/1e6:.0f}M"
        file_size = f"{size_info.get('file_size', {}).get('total_mb', 0):.0f}MB"
        flops = flops_info.get('flops', {}).get('per_example_formatted', 'N/A')
        auc = f"{metrics.get('auc', 0):.3f}"

        print(f"{name:<15} {params:<12} {file_size:<12} {flops:<15} {auc:<8}")

    print("=" * 80)